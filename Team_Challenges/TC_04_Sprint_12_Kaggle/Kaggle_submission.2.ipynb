{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-0YTYX-1Dv0"
      },
      "source": [
        "# **Kaggle ‚Äì DataTops¬Æ**\n",
        "Tu TA ha decidido cambiar de aires y, por eso, ha comprado una tienda de port√°tiles. Sin embargo, su √∫nica especialidad es Data Science, por lo que ha decidido crear un modelo de ML para establecer los mejores precios.\n",
        "\n",
        "¬øPodr√≠as ayudar a tu profe a mejorar ese modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b_oPcSD1Dv3"
      },
      "source": [
        "## Aspectos importantes\n",
        "- √öltima submission:\n",
        "    - Ma√±ana: 17 de febrero a las 5pm\n",
        "    - Tarde: 19 de febrero a las 5pm\n",
        "- **Enlace de la competici√≥n**: https://www.kaggle.com/t/c5cc87b50c4b4770bdc8f5acbe15577d\n",
        "- **Requisito**: Estar registrado en [Kaggle](https://www.kaggle.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLjH6XtL1Dv3"
      },
      "source": [
        "## M√©trica:\n",
        "El error cuadr√°tico medio (RMSE, por sus siglas en ingl√©s) es una medida de la desviaci√≥n est√°ndar de los residuos (errores de predicci√≥n). Los residuos representan la diferencia entre los valores observados y los valores predichos por el modelo. El RMSE indica qu√© tan dispersos est√°n estos errores: cuanto menor es el RMSE, m√°s cercanas est√°n las predicciones a los valores reales. En otras palabras, el RMSE mide qu√© tan bien se ajusta la l√≠nea de regresi√≥n a los datos.\n",
        "\n",
        "\n",
        "$$ RMSE = \\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}{\\Big(\\frac{d_i -f_i}{\\sigma_i}\\Big)^2}}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsfzFSuz1Dv4"
      },
      "source": [
        "## 1. Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW6W1-bd1Dv4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Oxf5-2G1Dv5"
      },
      "source": [
        "## 2. Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./data/train.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"./data/train.csv\")\n",
        "test  = pd.read_csv(\"./data/test.csv\")\n",
        "sample_sub = pd.read_csv(\"./data/sample_submission.csv\")\n",
        "\n",
        "print(\"train:\", train.shape)\n",
        "print(\"test:\", test.shape)\n",
        "print(\"sample:\", sample_sub.shape)\n",
        "train.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybAGcmnO1Dv5"
      },
      "source": [
        "### 2.1 Exploraci√≥n de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXQUY5DK1Dv5"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZhmjbtQ1Dv5"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihQFi2H21Dv5"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9TDfZEt1Dv5"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isna().sum().sort_values(ascending=False).head(20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.duplicated().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe(include=\"all\").T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = \"Price_in_euros\"\n",
        "\n",
        "df[target].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(df[target], bins=30)\n",
        "plt.title(\"Distribuci√≥n de Price_in_euros\")\n",
        "plt.xlabel(\"Price_in_euros\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Aqu√≠ solo creamos columnas m√°s ‚Äúanalizables‚Äù (num√©ricas). No borramos las originales.\n",
        "df_eda = df.copy()\n",
        "\n",
        "# RAM: \"8GB\" -> 8\n",
        "df_eda[\"Ram_GB\"] = df_eda[\"Ram\"].str.replace(\"GB\", \"\", regex=False).astype(float)\n",
        "\n",
        "# Weight: \"1.86kg\" -> 1.86\n",
        "df_eda[\"Weight_kg\"] = df_eda[\"Weight\"].str.replace(\"kg\", \"\", regex=False).astype(float)\n",
        "\n",
        "# ScreenResolution: extraer ancho y alto\n",
        "wh = df_eda[\"ScreenResolution\"].str.extract(r'(?P<width>\\d+)\\s*x\\s*(?P<height>\\d+)')\n",
        "df_eda[\"Screen_Width\"]  = wh[\"width\"].astype(float)\n",
        "df_eda[\"Screen_Height\"] = wh[\"height\"].astype(float)\n",
        "\n",
        "# PPI\n",
        "df_eda[\"PPI\"] = np.sqrt(df_eda[\"Screen_Width\"]**2 + df_eda[\"Screen_Height\"]**2) / df_eda[\"Inches\"]\n",
        "\n",
        "# Flags\n",
        "df_eda[\"Touchscreen\"] = df_eda[\"ScreenResolution\"].str.contains(\"Touchscreen\", case=False, na=False).astype(int)\n",
        "df_eda[\"IPS_Panel\"]   = df_eda[\"ScreenResolution\"].str.contains(\"IPS\", case=False, na=False).astype(int)\n",
        "\n",
        "# CPU: marca y GHz\n",
        "df_eda[\"Cpu_Brand\"] = df_eda[\"Cpu\"].str.split().str[0]\n",
        "df_eda[\"Cpu_GHz\"] = df_eda[\"Cpu\"].str.extract(r'(\\d+(\\.\\d+)?)\\s*GHz')[0].astype(float)\n",
        "\n",
        "# GPU: marca\n",
        "df_eda[\"Gpu_Brand\"] = df_eda[\"Gpu\"].str.split().str[0]\n",
        "\n",
        "df_eda[[\"Ram\", \"Ram_GB\", \"Weight\", \"Weight_kg\", \"ScreenResolution\", \"PPI\", \"Cpu\", \"Cpu_GHz\"]].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlaci√≥n con el target (solo num√©ricas)\n",
        "num_cols = df_eda.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "corr_target = df_eda[num_cols].corr()[target].drop(target)\n",
        "\n",
        "# Ordenar por valor absoluto \n",
        "corr_target = corr_target.reindex(corr_target.abs().sort_values(ascending=False).index)\n",
        "\n",
        "corr_target.head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colinealidad usando correlacion entre Features\n",
        "corr_matrix = df_eda[num_cols].corr().abs()\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(corr_matrix, aspect=\"auto\")\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(num_cols)), num_cols, rotation=90)\n",
        "plt.yticks(range(len(num_cols)), num_cols)\n",
        "plt.title(\"Correlaci√≥n absoluta entre variables num√©ricas\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ver variables categ√≥ricas\n",
        "cat_cols = df.select_dtypes(include=\"object\").columns\n",
        "\n",
        "cat_cols\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr = df_eda.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de correlaci√≥n SOLO num√©rica\n",
        "num_cols = df_corr.select_dtypes(include=np.number).columns\n",
        "\n",
        "corr_matrix = df_corr[num_cols].corr()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "plt.imshow(corr_matrix, aspect=\"auto\")\n",
        "plt.colorbar()\n",
        "\n",
        "plt.xticks(range(len(num_cols)), num_cols, rotation=90)\n",
        "plt.yticks(range(len(num_cols)), num_cols)\n",
        "\n",
        "plt.title(\"Matriz de correlaci√≥n (limpia)\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# correlaci√≥n entre variables num√©ricas y el target \n",
        "num_cols = df_corr.select_dtypes(include=np.number).columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_target = df_corr[num_cols].corr()[target]\n",
        "\n",
        "# quitar el propio target\n",
        "corr_target = corr_target.drop(target)\n",
        "\n",
        "# ordenar por importancia (valor absoluto)\n",
        "corr_target = corr_target.reindex(\n",
        "    corr_target.abs().sort_values(ascending=False).index\n",
        ")\n",
        "\n",
        "corr_target.head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "plt.barh(corr_target.index[:15], corr_target.values[:15])\n",
        "\n",
        "plt.title(\"Variables m√°s correlacionadas con el precio\")\n",
        "plt.xlabel(\"Correlaci√≥n\")\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6x5RxgS1Dv6"
      },
      "source": [
        "### 2.3 Definir X e y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir target\n",
        "target = \"Price_in_euros\"\n",
        "\n",
        "# X = todas las columnas excepto el target\n",
        "X = df.drop(columns=[target])\n",
        "\n",
        "# y = target\n",
        "y = df[target].copy()\n",
        "\n",
        "print(\"Shape X:\", X.shape)\n",
        "print(\"Shape y:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YhM9bjU1Dv6"
      },
      "source": [
        "### 2.4 Dividir X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divisi√≥n train / test (validaci√≥n interna)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,   # 20% para test interno\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_test :\", X_test.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"y_test :\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_engineering(df):\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # RAM: \"8GB\" -> 8\n",
        "    df[\"Ram_GB\"] = df[\"Ram\"].str.replace(\"GB\",\"\", regex=False).astype(float)\n",
        "\n",
        "    # Weight: \"1.86kg\" -> 1.86\n",
        "    df[\"Weight_kg\"] = df[\"Weight\"].str.replace(\"kg\",\"\", regex=False).astype(float)\n",
        "\n",
        "    # ScreenResolution -> width y height\n",
        "    wh = df[\"ScreenResolution\"].str.extract(r'(?P<width>\\d+)\\s*x\\s*(?P<height>\\d+)')\n",
        "\n",
        "    df[\"Screen_Width\"] = wh[\"width\"].astype(float)\n",
        "    df[\"Screen_Height\"] = wh[\"height\"].astype(float)\n",
        "\n",
        "    # PPI\n",
        "    df[\"PPI\"] = np.sqrt(df[\"Screen_Width\"]**2 + df[\"Screen_Height\"]**2) / df[\"Inches\"]\n",
        "\n",
        "    # Flags\n",
        "    df[\"Touchscreen\"] = df[\"ScreenResolution\"].str.contains(\"Touchscreen\", case=False, na=False).astype(int)\n",
        "    df[\"IPS_Panel\"] = df[\"ScreenResolution\"].str.contains(\"IPS\", case=False, na=False).astype(int)\n",
        "\n",
        "    # CPU GHz\n",
        "    df[\"Cpu_GHz\"] = df[\"Cpu\"].str.extract(r'(\\d+(\\.\\d+)?)\\s*GHz')[0].astype(float)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Engineering\n",
        "\n",
        "# Aplicar FE SOLO despu√©s del split\n",
        "\n",
        "X_train_fe = feature_engineering(X_train)\n",
        "X_test_fe  = feature_engineering(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aplicar get_dummies a train y test\n",
        "X_train_encoded = pd.get_dummies(X_train_fe, drop_first=True)\n",
        "X_test_encoded  = pd.get_dummies(X_test_fe, drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# alinear columnas\n",
        "X_train_encoded, X_test_encoded = X_train_encoded.align(\n",
        "    X_test_encoded,\n",
        "    join=\"left\",\n",
        "    axis=1,\n",
        "    fill_value=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"X_train_encoded:\", X_train_encoded.shape)\n",
        "print(\"X_test_encoded :\", X_test_encoded.shape)\n",
        "\n",
        "print(\"Columnas iguales:\", (X_train_encoded.columns == X_test_encoded.columns).all())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se aplica OneHotEncoding a las variables categ√≥ricas. Posteriormente se alinean las columnas entre train y test para asegurar que ambos conjuntos tengan exactamente las mismas features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQlw8Vdr1Dv6"
      },
      "source": [
        "## 3. Procesado de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPgDX-iM1Dv6"
      },
      "source": [
        "Nuestro target es la columna `Price_in_euros`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjzNxMU91Dv6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zATD1vpn1Dv6"
      },
      "source": [
        "-----------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojsM78OY1Dv6"
      },
      "source": [
        "## 4. Modelado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65rieXt81Dv6"
      },
      "source": [
        "### 4.1 Baseline de modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fOmhsmB1Dv6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "\n",
        "# Crear modelo baseline\n",
        "rf_model = RandomForestRegressor(\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "rf_model.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Predicciones en test interno\n",
        "predictions = rf_model.predict(X_test_encoded)\n",
        "\n",
        "# M√©trica RMSE\n",
        "rmse = root_mean_squared_error(y_test, predictions)\n",
        "\n",
        "print(\"RMSE baseline:\", rmse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br9_gKrL1Dv6"
      },
      "source": [
        "### 4.2 Sacar m√©tricas, valorar los modelos\n",
        "\n",
        "Recuerda que en la competici√≥n se va a evaluar con la m√©trica de ``RMSE``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSN5UZAE1Dv7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calcular m√©tricas\n",
        "\n",
        "rmse = root_mean_squared_error(y_test, predictions)\n",
        "mae  = mean_absolute_error(y_test, predictions)\n",
        "r2   = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAE :\", mae)\n",
        "print(\"R2  :\", r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imOqya6z1Dv7"
      },
      "source": [
        "### 4.3 Optimizaci√≥n (up to you ü´∞üèª)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx5MCFni1Dv7"
      },
      "source": [
        "-----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV7xlHP01Dv7"
      },
      "source": [
        "## Una vez listo el modelo, toca predecir ``test.csv``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWUBEtcP1Dv7"
      },
      "source": [
        "**RECUERDA: APLICAR LAS TRANSFORMACIONES QUE HAYAS REALIZADO EN `train.csv` a `test.csv`.**\n",
        "\n",
        "\n",
        "V√©ase:\n",
        "- Estandarizaci√≥n/Normalizaci√≥n\n",
        "- Eliminaci√≥n de Outliers\n",
        "- Eliminaci√≥n de columnas\n",
        "- Creaci√≥n de columnas nuevas\n",
        "- Gesti√≥n de valores nulos\n",
        "- Y un largo etc√©tera de t√©cnicas que como Data Scientist hayas considerado las mejores para tu dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uOZ30nP1Dv7"
      },
      "source": [
        "## 1. Carga los datos de `test.csv` para predecir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbTMLc3w1Dv7"
      },
      "outputs": [],
      "source": [
        "X_pred = pd.read_csv(\"./data/test.csv\")\n",
        "X_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66MczL1e1Dv7"
      },
      "outputs": [],
      "source": [
        "X_pred.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6eGCkhQ1Dv7"
      },
      "outputs": [],
      "source": [
        "X_pred.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WA_TDy81Dv7"
      },
      "source": [
        " ## 2. Replicar el procesado para ``test.csv``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_pred_fe = feature_engineering(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) aplicar FE al test\n",
        "X_pred_fe = feature_engineering(test)\n",
        "\n",
        "# 2) dummies\n",
        "X_pred = pd.get_dummies(X_pred_fe, drop_first=True)\n",
        "\n",
        "# 3) alinear con train\n",
        "X_pred_aligned = X_pred.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
        "\n",
        "# 4) predecir\n",
        "predictions_submit = rf_model.predict(X_pred_aligned)\n",
        "\n",
        "len(predictions_submit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmTeHhx61Dv7"
      },
      "outputs": [],
      "source": [
        "X_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_submit = rf_model.predict(X_pred_aligned)\n",
        "predictions_submit[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(predictions_submit)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm1E4KZC1Dv8"
      },
      "source": [
        "**¬°OJO! ¬øPor qu√© me da error?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51qH2nmY1Dv8"
      },
      "source": [
        "IMPORTANTE:\n",
        "\n",
        "- SI EL ARRAY CON EL QUE HICISTEIS `.fit()` ERA DE 4 COLUMNAS, PARA `.predict()` DEBEN SER LAS MISMAS\n",
        "- SI AL ARRAY CON EL QUE HICISTEIS `.fit()` LO NORMALIZASTEIS, PARA `.predict()` DEB√âIS NORMALIZARLO\n",
        "- TODO IGUAL SALVO **BORRAR FILAS**, EL N√öMERO DE ROWS SE DEBE MANTENER EN ESTE SET, PUES LA PREDICCI√ìN DEBE TENER **391 FILAS**, SI O SI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEJRE2TD1Dv8"
      },
      "source": [
        "**Entonces, si al cargar los datos de ``train.csv`` usaste `index_col=0`, ¬øtendr√© que hacer lo tambi√©n para el `test.csv`?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc6QsmVs1Dv8"
      },
      "outputs": [],
      "source": [
        "# ¬øQu√© opin√°is?\n",
        "# ¬øS√≠, no?."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VLUSmwh1Dv8"
      },
      "source": [
        "![wow.jpeg](attachment:wow.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv_-fwkS1Dv8"
      },
      "source": [
        "## 3. **¬øQu√© es lo que subir√°s a Kaggle?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfsoAjbO1Dv8"
      },
      "source": [
        "**Para subir a Kaggle la predicci√≥n esta tendr√° que tener una forma espec√≠fica.**\n",
        "\n",
        "En este caso, la **MISMA** forma que `sample_submission.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) reconstruir sample limpio (variable que usa el chequeador)\n",
        "sample = pd.read_csv(\"./data/sample_submission.csv\")\n",
        "\n",
        "# 2) reconstruir submission desde la plantilla\n",
        "submission = sample.copy()\n",
        "\n",
        "# 3) meter predicciones (aseg√∫rate de que predictions_submit existe y tiene 391 valores)\n",
        "price_col = [c for c in submission.columns if \"price\" in c.lower()][0]\n",
        "submission[price_col] = predictions_submit\n",
        "\n",
        "print(\"sample shape:\", sample.shape)\n",
        "print(\"submission shape:\", submission.shape)\n",
        "print(\"IDs iguales:\", submission[\"laptop_ID\"].equals(sample[\"laptop_ID\"]))\n",
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = pd.read_csv(\"./data/sample_submission.csv\")  # IMPORTANT√çSIMO: el chequeador usa 'sample'\n",
        "print(\"sample shape:\", sample.shape)\n",
        "print(sample.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "submission = sample.copy()\n",
        "\n",
        "price_col = [c for c in submission.columns if \"price\" in c.lower()][0]\n",
        "submission[price_col] = predictions_submit\n",
        "\n",
        "print(\"submission shape:\", submission.shape)\n",
        "print(submission.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ZUO8pF1Dv8"
      },
      "source": [
        "## 4. Mete tus predicciones en un dataframe llamado ``submission``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKVRMDUY1Dv8"
      },
      "outputs": [],
      "source": [
        "#¬øC√≥mo creamos la submission?\n",
        "submission = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn2nLy6c1Dv8"
      },
      "outputs": [],
      "source": [
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY1MluFr1Dv9"
      },
      "outputs": [],
      "source": [
        "submission.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"sample shape:\", sample.shape)\n",
        "print(\"submission shape:\", submission.shape)\n",
        "\n",
        "print(sample.columns)\n",
        "print(submission.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qMGcOJq1Dv9"
      },
      "source": [
        "## 5. P√°sale el CHEQUEADOR para comprobar que efectivamente est√° listo para subir a Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFxk4hYQ1Dv9"
      },
      "outputs": [],
      "source": [
        "def chequeador(df_to_submit):\n",
        "    \"\"\"\n",
        "    Esta funci√≥n se asegura de que tu submission tenga la forma requerida por Kaggle.\n",
        "\n",
        "    Si es as√≠, se guardar√° el dataframe en un `csv` y estar√° listo para subir a Kaggle.\n",
        "\n",
        "    Si no, LEE EL MENSAJE Y HAZLE CASO.\n",
        "\n",
        "    Si a√∫n no:\n",
        "    - apaga tu ordenador,\n",
        "    - date una vuelta,\n",
        "    - enciendelo otra vez,\n",
        "    - abre este notebook y\n",
        "    - leelo todo de nuevo.\n",
        "    Todos nos merecemos una segunda oportunidad. Tambi√©n t√∫.\n",
        "    \"\"\"\n",
        "    if df_to_submit.shape == sample.shape:\n",
        "        if df_to_submit.columns.all() == sample.columns.all():\n",
        "            if df_to_submit.laptop_ID.all() == sample.laptop_ID.all():\n",
        "                print(\"You're ready to submit!\")\n",
        "                df_to_submit.to_csv(\"submission.csv\", index = False) #muy importante el index = False\n",
        "                urllib.request.urlretrieve(\"https://www.mihaileric.com/static/evaluation-meme-e0a350f278a36346e6d46b139b1d0da0-ed51e.jpg\", \"gfg.png\")\n",
        "                img = Image.open(\"gfg.png\")\n",
        "                img.show()\n",
        "            else:\n",
        "                print(\"Check the ids and try again\")\n",
        "        else:\n",
        "            print(\"Check the names of the columns and try again\")\n",
        "    else:\n",
        "        print(\"Check the number of rows and/or columns and try again\")\n",
        "        print(\"\\nMensaje secreto del TA: No me puedo creer que despu√©s de todo este notebook hayas hecho alg√∫n cambio en las filas de `test.csv`. Lloro.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnZqqe131Dv9"
      },
      "outputs": [],
      "source": [
        "chequeador(submission)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
